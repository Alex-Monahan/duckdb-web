---
layout: post
title: "Fast Top N Aggregation and Filtering with DuckDB"
author: "Alex Monahan"
excerpt: "Find the top N values or filter to the latest N rows more quickly and easily with the `N` parameter in the `min`, `max`, `min_by`, and `max_by` aggregate functions."
---

## Introduction to Top N

A common pattern when analyzing data is to look for the rows of data that are the highest or lowest in a particular metric.
When interested in the highest or lowest `N` rows in an entire dataset, SQL's standard `ORDER BY` and `LIMIT` clauses will sort by the metric of interest and only return `N` rows.
For example:

<!-- TODO: Add in the truncated results for these queries -->

```sql
-- Generate an example TPCH dataset
call dbgen(sf=1);

-- Return the most recent 3 rows by l_shipdate
FROM lineitem 
ORDER BY 
    l_shipdate DESC 
LIMIT 3;
```

| l_orderkey | l_partkey | ... | l_shipmode |              l_comment              |
|-----------:|----------:|-----|------------|-------------------------------------|
| 354528     | 6116      | ... | MAIL       | wake according to the u             |
| 413956     | 16402     | ... | SHIP       | usual patterns. carefull            |
| 484581     | 10970     | ... | TRUCK      | ccounts maintain. dogged accounts a |

This is useful to quickly get the oldest or newest values in a dataset or to find outliers in a particular metric.

Another common approach is to query the min/max summary statistics of one or more columns. 
This can find outliers, but the row that contains the outlier can be different for each column, so it is answering a different question.
DuckDB's helpful `COLUMNS` expression allows us to calculate the maximum value for all columns.

```sql
FROM lineitem
SELECT 
    MAX(COLUMNS(*));
```

| l_orderkey | l_partkey | ... | l_shipmode |  l_comment  |
|-----------:|----------:|-----|------------|-------------|
| 600000     | 20000     | ... | TRUCK      | zzle. slyly |

However, these two approaches can only answer certain kinds of questions. 
There are many scenarios where the goal is to understand the top N values *within a group*.
In the first example above, how would we calculate the last 10 shipments from each supplier?
SQL's `LIMIT` clause is not able to handle that situation. 
Let's call this type of analysis the top N by group. 

This type of analysis is a common tool for exploring new datasets. 
Use cases include pulling the most recent few rows for each group or finding the most extreme few values in a group.
Sticking with our shipment example, we could look at the last 10 shipments of each part number, or find the 5 highest priced orders per customer. 

## Traditional Top N by Group

In most databases, the way to filter to the top N within a group is to use a window function and a Common Table Expression (CTE). 
This approach also works in DuckDB.
For example, this query returns the 3 most recent shipments for each supplier:

```sql
WITH ranked_lineitem as (
    FROM lineitem 
    SELECT 
        *,
        row_number() OVER (PARTITION BY l_suppkey ORDER BY l_shipdate DESC) as my_ranking
)
FROM ranked_lineitem
WHERE 
    my_ranking <= 3;
```

| l_orderkey | l_partkey | l_suppkey | ... | l_shipmode |                 l_comment                 | my_ranking |
|-----------:|----------:|----------:|-----|------------|-------------------------------------------|-----------:|
| 1310688    | 169532    | 7081      | ... | RAIL       | ully final exc                            | 1          |
| 910561     | 194561    | 7081      | ... | SHIP       | ly bold excuses caj                       | 2          |
| 4406883    | 179529    | 7081      | ... | RAIL       | tions. furious                            | 3          |
| 4792742    | 52095     | 7106      | ... | RAIL       | onic, ironic courts. final deposits sleep | 1          |
| 4010212    | 122081    | 7106      | ... | MAIL       |  accounts cajole finally ironic instruc   | 2          |
| 1220871    | 94596     | 7106      | ... | TRUCK      | regular requests above t                  | 3          |
| ...   | ...   | ...   | ...   | ...   | ...   | ...   |

In DuckDB, this can be simplified using the `QUALIFY` clause.
`QUALIFY` acts like a `WHERE` clause, but specifically operates on the results of window functions. 
By making this adjustment, the CTE can be avoided while returning the same results.

```sql
FROM lineitem 
SELECT 
    *,
    row_number() OVER (PARTITION BY l_suppkey ORDER BY l_shipdate DESC) as my_ranking
QUALIFY
    my_ranking <= 3;
```

This is certainly a viable approach!
However, what are its weaknesses? 
Even though the query is interested in only the 3 most recent shipments, it must sort every shipment just to retrieve those top 3.
Sorting in DuckDB has a complexity of `O(kn)` due to DuckDB's innovative [Radix sort implementation]({% post_url 2021-08-27-external-sorting %}), but this is still higher than the `O(n)` of [DuckDB's hash aggregate]({% post_url 2024-03-29-external-aggregation %}), for example.
Sorting is also a memory intensive operation when compared with aggregation. 


## Top N in DuckDB

DuckDB 1.1 added a new capability to dramatically simplify and improve performance of top N calculations.
The functions `min`, `max`, `min_by`, and `max_by` all now accept an optional parameter `N`.
If `N` is greater than 1 (the default), they will return an array of the top values.

As a simple example, let's query the most recent (top 3) shipment dates:

```sql
FROM lineitem
SELECT 
    MAX(l_shipdate, 3) as top_3_shipdates;
```

|           top_3_shipdates            |
|--------------------------------------|
| [1998-12-01, 1998-12-01, 1998-12-01] |

## Top N by Column in DuckDB

This can become even more useful thanks to the `COLUMNS` expression once again - we can retrieve the 3 top values in each column. 
We can call this a top N by column analysis. 
It is particularly messy to try to do this analysis with ordinary SQL!
You would need a subquery or window function for every single column...
In DuckDB, simply:

```sql
FROM lineitem
SELECT 
    MAX(COLUMNS(*), 3) as "top_3_\0";
```

|     top_3_l_orderkey     |    top_3_l_partkey    | ... |   top_3_l_shipmode    |                               top_3_l_comment                                |
|--------------------------|-----------------------|-----|-----------------------|------------------------------------------------------------------------------|
| [600000, 600000, 599975] | [20000, 20000, 20000] | ... | [TRUCK, TRUCK, TRUCK] | [zzle. slyly, zzle. quickly bold a, zzle. pinto beans boost slyly slyly fin] |

## Top N by Group in DuckDB

Armed with the new `N` parameter, how can we speed up a top N by group analysis?

Want to cut to the chase and see the final output? 
[Feel free to skip ahead!](#the-final-top-n-by-group-query)

We will take advantage of three other DuckDB SQL features to make this possible:
* The [`max_by` function]({% link docs/sql/functions/aggregates.md %}#max_byarg-val-n) (also known as `arg_max`)
* The [`UNNEST` function]({% link docs/sql/query_syntax/unnest.md %})
* Automatically packing an entire row into a [`STRUCT` column]({% link docs/sql/data_types/struct.md %}#creating-structs)

The `max` function will return the max (or now the max N!) of a specific column.
In contrast, the `max_by` function will find the maximum value in a column, and then retrieve a value from the same row, but a different column.
For example, this query will return the ids of the 3 most recently shipped orders for each supplier:

```sql
FROM lineitem
SELECT 
    l_suppkey,
    max_by(l_orderkey, l_shipdate, 3) as recent_orders
GROUP BY
    l_suppkey;
```

| l_suppkey |        recent_orders        |
|----------:|-----------------------------|
| 2992      | [233573, 3597639, 3060227]  |
| 8516      | [4675968, 5431174, 4626530] |
| 3205      | [3844610, 4396966, 3405255] |
| 2152      | [1672000, 4209601, 3831138] |
| 1880      | [4852999, 2863747, 1650084] |
| ...       | ...                         |


The `max_by` function is an aggregate function, so it takes advantage of DuckDB's fast hash aggregation rather than sorting.
Instead of sorting by `l_shipdate`, the `max_by` function scans through the dataset just once and keeps track of the `N` highest `l_shipdate` values. 
It then returns the order id that corresponds with each of the most recent shipment dates.
The radix sort in DuckDB must scan through the dataset once per byte, so scanning only once providing a significant speedup.
For example, if sorting by a 64-bit integer, the sort algorithm must loop through the dataset 8 times vs. 1 with this approach!
A simple benchmark is included below.

However, this SQL query has a few gaps.
The query returns results as a `LIST` rather than as separate rows. 
Thankfully the `UNNEST` function can split a `LIST` into separate rows:

```sql
FROM lineitem
SELECT 
    l_suppkey,
    UNNEST(
        max_by(l_orderkey, l_shipdate, 3)
    ) as recent_orders
GROUP BY
    l_suppkey;
```

| l_suppkey | recent_orders |
|----------:|--------------:|
| 2576      | 930468        |
| 2576      | 2248354       |
| 2576      | 3640711       |
| 5559      | 4022148       |
| 5559      | 1675680       |
| 5559      | 4976259       |
| ...       | ...           |

The next gap is that there is no way to easily see the `l_shipdate` associated with the returned `l_orderkey` values.
This query only returns a single column, while typically a top N by group analysis will require the entire row.

However, DuckDB allows us to refer to the entire contents of a row as if it were just a single column!
By referring to the name of the table itself (here, `lineitem`) instead of the name of a column, the `max_by` function can retrieve all columns. 

```sql
FROM lineitem
SELECT 
    l_suppkey,
    UNNEST(
        max_by(lineitem, l_shipdate, 3)
    ) as recent_orders
GROUP BY
    l_suppkey;
```

| l_suppkey | recent_orders |
|----------:|------------------------------------------------------------------------|
| 5411      | {'l_orderkey': 2543618, 'l_partkey': 105410, 'l_suppkey': 5411, ... |
| 5411      | {'l_orderkey': 580547, 'l_partkey': 130384, 'l_suppkey': 5411, ...  |
| 5411      | {'l_orderkey': 3908642, 'l_partkey': 132897, 'l_suppkey': 5411, ... |
| 90        | {'l_orderkey': 4529697, 'l_partkey': 122553, 'l_suppkey': 90, ... |
| 90        | {'l_orderkey': 4473346, 'l_partkey': 160089, 'l_suppkey': 90, ... |
| ...       | ...           |

Well that isn't so friendly looking! 

### The Final Top N by Group Query

Passing in one more argument to `UNNEST` will split this out into separate columns.
The `l_suppkey` column can also be excluded, since it will automatically be included already.

```sql
FROM lineitem
SELECT 
    UNNEST(
        max_by(lineitem, l_shipdate, 3),
        recursive:=1
    ) as recent_orders
GROUP BY
    l_suppkey;
```

| l_orderkey | l_partkey | l_suppkey | ... |  l_shipinstruct   | l_shipmode |                  l_comment                  |
|-----------:|----------:|----------:|-----|-------------------|------------|---------------------------------------------|
| 1234726    | 6875      | 6876      | ... | COLLECT COD       | FOB        |  cajole carefully slyly fin                 |
| 2584193    | 51865     | 6876      | ... | TAKE BACK RETURN  | TRUCK      | fully regular deposits at the q             |
| 2375524    | 26875     | 6876      | ... | DELIVER IN PERSON | AIR        | nusual ideas. busily bold deposi            |
| 5751559    | 95626     | 8136      | ... | NONE              | SHIP       | ers nag fluffily against the spe            |
| 3103457    | 103115    | 8136      | ... | TAKE BACK RETURN  | FOB        | y slyly express warthogs-- unusual, e       |
| 5759105    | 178135    | 8136      | ... | COLLECT COD       | TRUCK      | es. regular pinto beans haggle.             |
| ...   | ...   | ...   | ...   | ...   | ...   | ...   |

> Note This approach can also be useful for the common task of de-duplicating by finding the latest value within a group.
> Simply use an `N` of 1!

## Performance Comparisons

## Conclusion

<!-- Talk about time and memory -->